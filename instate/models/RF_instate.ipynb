{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF ML Model (to aid basic interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc = {'figure.figsize':(15, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 35.9 s, total: 3min 4s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NGRAMS = 2\n",
    "SAMPLE = 1000000\n",
    "\n",
    "# Florida voter\n",
    "df = pd.read_csv('instate_processed_clean.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421190808, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's sample as my df is pretty big (and let's overwrite)\n",
    "df = df.sample(n = 400000, replace=False, random_state=31415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat last name and first name\n",
    "df['state_id'] = df.state.factorize()[0]\n",
    "X = df.last_name\n",
    "y = df.state_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_id_df = df[['state', 'state_id']].drop_duplicates().sort_values('state_id')\n",
    "state_to_id = dict(state_id_df.values)\n",
    "id_to_state = dict(state_id_df[['state_id', 'state']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 455)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vect = TfidfVectorizer(analyzer='char', sublinear_tf=True, min_df=5, norm='l2', ngram_range=(1, NGRAMS), lowercase=False)\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=10, ngram_range=(1, NGRAMS)) \n",
    "\n",
    "features = vect.fit_transform(df.last_name).toarray()\n",
    "labels = df.state_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "#N = 5\n",
    "#for state, state_id in sorted(state_to_id.items()):\n",
    "#  features_chi2 = chi2(features, labels == state_id)\n",
    "#  indices = np.argsort(features_chi2[0])\n",
    "#  feature_names = np.array(vect.get_feature_names_out())[indices]\n",
    "#  unigrams = [v for v in feature_names if len(v) == 1]\n",
    "#  bigrams = [v for v in feature_names if len(v) == 2]\n",
    "#  print(\"# '{}':\".format(state))\n",
    "#  print(\"  . Most correlated unigrams:\\n       . {}\".format('\\n       . '.join(unigrams[-N:])))\n",
    "#  print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "\n",
    "# build n-gram list\n",
    "\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(1, NGRAMS), lowercase=False) \n",
    "#vect = TfidfVectorizer(analyzer='char', sublinear_tf=True, min_df=5, norm='l2', ngram_range=(1, NGRAMS), lowercase=False)\n",
    "X_train = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6733125\n",
      "CPU times: user 14min 35s, sys: 53.3 ms, total: 14min 35s\n",
      "Wall time: 14min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state=21)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_test = vect.transform(X_test).toarray()\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     andaman       0.57      0.71      0.63     12784\n",
      "      andhra       0.83      0.90      0.86     15529\n",
      "   arunachal       0.39      0.21      0.28      3536\n",
      "       assam       0.67      0.32      0.43      3432\n",
      "       bihar       0.46      0.69      0.55     13036\n",
      "  chandigarh       0.42      0.04      0.08      2325\n",
      "       dadra       0.76      0.23      0.36      3815\n",
      "       daman       0.66      0.56      0.60      1816\n",
      "       delhi       0.77      0.62      0.69      1780\n",
      "         goa       0.81      0.84      0.83      4434\n",
      "         guj       0.90      0.83      0.86      4296\n",
      "         har       0.92      0.94      0.93      6703\n",
      "         jha       0.81      0.66      0.72      1073\n",
      "          jk       0.67      0.47      0.55      1219\n",
      "         kar       0.76      0.64      0.70       189\n",
      "      kerala       0.86      0.75      0.80      1233\n",
      " maharashtra       0.39      0.06      0.10      1115\n",
      "     manipur       0.90      0.81      0.85       314\n",
      "   meghalaya       0.75      0.52      0.62       391\n",
      "     mizoram       0.00      0.00      0.00       102\n",
      "          mp       0.93      0.46      0.61        59\n",
      "    nagaland       0.80      0.30      0.43       269\n",
      "         odi       0.67      0.08      0.15        24\n",
      "  puducherry       0.85      0.77      0.81       144\n",
      "      punjab       0.67      0.30      0.42       129\n",
      "   rajasthan       0.66      0.65      0.66        69\n",
      "      sikkim       0.00      0.00      0.00        28\n",
      "         tel       0.50      0.36      0.42        28\n",
      "     tripura       0.43      0.10      0.16        30\n",
      "          up       0.50      0.09      0.15        33\n",
      "         utt       0.86      0.49      0.63        65\n",
      "\n",
      "    accuracy                           0.67     80000\n",
      "   macro avg       0.65      0.47      0.51     80000\n",
      "weighted avg       0.68      0.67      0.65     80000\n",
      "\n",
      "[[ 9064   290   267    37  2847     2    94    27    20    17     7    52\n",
      "     12    31     0     3     6     0     5     0     0     0     0     0\n",
      "      1     2     0     0     0     0     0]\n",
      " [  141 14037    18    39   631    10    26    11    11   150   285    72\n",
      "     30    35     3    22     3     0     1     0     0     0     1     1\n",
      "      2     0     0     0     0     0     0]\n",
      " [  603   135   751   167  1761    19     8    56     1     6     3    13\n",
      "      5     2     0     2     3     0     0     0     0     0     0     0\n",
      "      0     1     0     0     0     0     0]\n",
      " [  276   197   111  1092  1585    20    19    23     7    33     9    13\n",
      "      2     8     1    15    16     0     3     0     0     0     0     1\n",
      "      0     0     1     0     0     0     0]\n",
      " [ 2606   631   252   137  9036    39    37   110    16    17    30    59\n",
      "     14    24     0     5    16     1     3     0     0     0     0     1\n",
      "      2     0     0     0     0     0     0]\n",
      " [  341    86   247    25  1273    97     3   205    13     5     0    13\n",
      "      1     4     0     1    10     0     1     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [ 1980    88    75    30   545     1   893     9     3    11     5    99\n",
      "      3    51     0     3    11     0     7     0     0     1     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [  160    36    83    20   466    17     2  1009     6     4     2     9\n",
      "      1     0     0     0     1     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [   55    50    56    24   262     5     7    15  1105    91     0    19\n",
      "     26    15     5     5    10     5     3     0     1     1     0     3\n",
      "      0     9     2     3     0     2     1]\n",
      " [   15   314     2    15    64     2    11     6    38  3744    14    67\n",
      "     33    12    14    53     3     2     0     0     0     7     0     3\n",
      "      5     1     3     2     1     0     3]\n",
      " [   20   608     1     1    45     1     1     4     3    33  3557    12\n",
      "      2     3     0     2     0     0     0     0     0     1     0     1\n",
      "      0     0     0     0     1     0     0]\n",
      " [   19   110     3     6    71     2    32     9    20    72     9  6278\n",
      "      8    36     1    10     7     1     9     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [   13   111     0     0    70     1     5     6    34    78     5    11\n",
      "    706     2     6     7     1     1     0     0     0     3     0     6\n",
      "      0     2     3     2     0     0     0]\n",
      " [  222    35     4     2   271     1    13     2    14     7     2    28\n",
      "      0   575     0     1     7     0    33     0     0     0     0     0\n",
      "      1     1     0     0     0     0     0]\n",
      " [    2    11     0     1     3     0     0     2     6    24     1     2\n",
      "      5     0   121     7     0     1     0     0     0     0     0     1\n",
      "      1     0     0     0     0     1     0]\n",
      " [    8    88     2     8    14     1     1     0     6   135     3    27\n",
      "      5     3     6   921     0     3     0     0     0     1     0     1\n",
      "      0     0     0     0     0     0     0]\n",
      " [  281    39    40    17   616     9     2    14     7     5     2     9\n",
      "      0     5     0     2    67     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    3     4     0     0     2     1     0     0    11    16     0     7\n",
      "      1     5     0     1     1   255     1     0     1     1     0     0\n",
      "      2     2     0     0     0     0     0]\n",
      " [   71    10     2     0    45     0     5     1     0     1     0     2\n",
      "      0    37     0     0     8     4   205     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [   15     5     5     2    57     2     2    10     0     1     0     2\n",
      "      0     0     0     0     1     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    2     4     0     0     3     0     1     0     4     6     0     3\n",
      "      0     1     0     2     0     2     0     0    27     2     0     0\n",
      "      0     2     0     0     0     0     0]\n",
      " [    3    31     1     0    11     0     1     1    60    47     5     4\n",
      "      7     7     0     2     0     3     0     0     0    80     0     0\n",
      "      4     0     0     0     1     0     1]\n",
      " [    0     3     0     0     1     0     0     0     2     8     2     1\n",
      "      2     1     1     0     0     0     0     0     0     0     2     0\n",
      "      0     0     0     0     1     0     0]\n",
      " [    3     6     0     0     6     0     2     0     3     6     2     2\n",
      "      2     0     0     1     0     0     0     0     0     0     0   111\n",
      "      0     0     0     0     0     0     0]\n",
      " [    3    12     0     0     5     0     0     0     9    28     1     4\n",
      "      4     3     0     7     1     5     1     0     0     3     0     0\n",
      "     39     1     0     3     0     0     0]\n",
      " [    1     2     0     0     0     0     1     1    10     6     0     1\n",
      "      0     0     1     0     0     1     0     0     0     0     0     0\n",
      "      0    45     0     0     0     0     0]\n",
      " [    0     5     0     0     1     0     0     0     6     8     1     1\n",
      "      4     0     0     1     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     2     0     0     0     0     0     0     7     6     0     0\n",
      "      0     0     0     2     0     0     0     0     0     0     0     0\n",
      "      1     0     0    10     0     0     0]\n",
      " [    0     2     0     0     0     0     1     0     2     6    15     0\n",
      "      0     0     0     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     3     0     0]\n",
      " [    0     2     2     0     2     0     1     0     9     8     0     4\n",
      "      0     2     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     3     0]\n",
      " [    0     5     0     0     1     0     0     0     0    19     1     2\n",
      "      2     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     2     0     0     0     0    32]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyter/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyter/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names = list(df.state.astype('category').cat.categories)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, \"instate_lname_rf_model.joblib\", compress=3)  # compression is ON!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
