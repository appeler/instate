{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1719941232006,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"Wv_fU958mVDM","outputId":"9052351a-1044-4d86-bde0-bc58587d89a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab/instate_v2\n"]}],"source":["%cd /content/drive/MyDrive/Colab/instate_v2/"]},{"cell_type":"markdown","metadata":{"id":"OXPiM3eJmXmY"},"source":["# Extract last names\n","In the current given dataset, we have states that have names with english and states with non-english."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDi3DzzemiNR"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"PLpE3ERfOroh"},"source":["## Processing states has names in english"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1718745864674,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"kBmFefjNPCu4","outputId":"e61be1e1-6995-4b6e-af7d-987394206c31"},"outputs":[{"name":"stdout","output_type":"stream","text":["15\n"]}],"source":["# total states\n","!ls -ltr data/clean | grep -v \"_ln.csv\" | grep \"csv\" | wc -l"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":478,"status":"ok","timestamp":1718737119247,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"gSuM5pLVmlEq","outputId":"38ce2387-b03c-44ea-afda-471d1c8c5541"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 18762410\n","-rw------- 1 root root 7063645140 Apr 25 23:26 andhra.csv\n","-rw------- 1 root root  220875368 Apr 25 23:58 arunachal.csv\n","-rw------- 1 root root   30437784 Apr 28 07:59 dadra.csv\n","-rw------- 1 root root   29861386 Apr 28 08:04 daman.csv\n","-rw------- 1 root root 4655371427 May 24 22:40 delhi.csv\n","-rw------- 1 root root  304924618 May 24 22:47 goa.csv\n","-rw------- 1 root root   45260206 May 24 22:50 jk.csv\n","-rw------- 1 root root  458125766 May 24 22:51 manipur.csv\n","-rw------- 1 root root  438116162 May 24 22:53 meghalaya.csv\n","-rw------- 1 root root  191618060 May 24 22:54 mizoram.csv\n","-rw------- 1 root root  262045318 May 24 22:55 nagaland.csv\n","-rw------- 1 root root  316673687 May 24 22:56 puducherry.csv\n","-rw------- 1 root root   89363047 May 24 23:19 sikkim.csv\n","-rw------- 1 root root 5046609351 May 24 23:43 kerala.csv\n","-rw------- 1 root root   58581352 Jun 18 18:58 andaman.csv\n"]}],"source":["# below are the states that have names in english\n","!ls -ltr data/clean | grep -v \"_ln.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401,"status":"ok","timestamp":1718738335271,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"6y_rkTh0tdPy","outputId":"dfbef2ff-e69c-4bf6-8c1f-0bd54ce4b95e"},"outputs":[{"name":"stdout","output_type":"stream","text":["6.6G\tdata/clean/andhra.csv\n","211M\tdata/clean/arunachal.csv\n","30M\tdata/clean/dadra.csv\n","29M\tdata/clean/daman.csv\n","4.4G\tdata/clean/delhi.csv\n","291M\tdata/clean/goa.csv\n","44M\tdata/clean/jk.csv\n","437M\tdata/clean/manipur.csv\n","418M\tdata/clean/meghalaya.csv\n","183M\tdata/clean/mizoram.csv\n","250M\tdata/clean/nagaland.csv\n","303M\tdata/clean/puducherry.csv\n","86M\tdata/clean/sikkim.csv\n","4.8G\tdata/clean/kerala.csv\n","56M\tdata/clean/andaman.csv\n"]}],"source":["# get size of above files\n","!ls -ltr data/clean | grep -v \"_ln.csv\" | awk '{print $9}' | xargs -I % du -sh data/clean/%"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waPqKsUvyIWr"},"outputs":[],"source":["# Function to normalize names and return a set of possible last names\n","def get_possible_last_names(name):\n","    parts = name.split(' ')\n","    return set(parts)\n","\n","\n","# Helper function to extract last names and filter out invalid ones\n","def extract_valid_last_name(name1, name2):\n","    # Split the names by space\n","    parts1 = name1.split()\n","    parts2 = name2.split()\n","\n","    # Extract the last names\n","    last_name1 = parts1[-1] if len(parts1) > 1 else ''\n","    last_name2 = parts2[-1] if len(parts2) > 1 else ''\n","\n","    # Check if the last names are valid (not a single or double letter) and match\n","    if last_name1 == last_name2 and len(last_name1) > 2:\n","        return last_name1\n","    else:\n","        return None\n","\n","\n","def process_lastnames(file, state, path=\"data/final\"):\n","    df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n","\n","    # drop na values in columns elector_name and father_or_husband_name\n","    df = df.dropna(subset=['elector_name', 'father_or_husband_name'])\n","\n","    # Normalize the names\n","    df['last_names1'] = df['elector_name'].apply(get_possible_last_names)\n","    df['last_names2'] = df['father_or_husband_name'].apply(get_possible_last_names)\n","\n","    # Find matching rows by checking for intersections in the sets of last names\n","    df = df[df.apply(lambda row: len(row['last_names1'].intersection(row['last_names2'])) > 0, axis=1)]\n","    # extract last name\n","    df['last_name'] = df.apply(lambda row: next(iter(row['last_names1'].intersection(row['last_names2'])),''), axis=1)\n","    # Filter out the rows where last_name is None\n","    df = df.dropna(subset=['last_name'])\n","    # Convert the last_name column to lowercase\n","    df['last_name'] = df['last_name'].str.lower()\n","    # Remove any last names less than 3\n","    df = df[df['last_name'].str.len() >= 3]\n","    # Get the value counts of the last names\n","    last_name_counts = df['last_name'].value_counts()\n","    # Convert the Series to a DataFrame\n","    last_name_counts_df = last_name_counts.reset_index()\n","    last_name_counts_df.columns = ['last_name', 'count']\n","    # Add the state column\n","    last_name_counts_df['state'] = state\n","    # Save the DataFrame to a CSV file\n","    last_name_counts_df.to_csv(f'{path}/{state}_ln.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMMFgMfqyoIt"},"outputs":[],"source":["states_w_eng_names = !ls -ltr data/clean | grep -v \"_ln.csv\" | grep \"csv\" | awk '{print $9}'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1718741349205,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"kaI5H-9b9n6R","outputId":"8f73baf9-3d01-4d91-b54b-2dce9d3c7254"},"outputs":[{"data":{"text/plain":["['andhra.csv',\n"," 'arunachal.csv',\n"," 'dadra.csv',\n"," 'daman.csv',\n"," 'delhi.csv',\n"," 'goa.csv',\n"," 'jk.csv',\n"," 'manipur.csv',\n"," 'meghalaya.csv',\n"," 'mizoram.csv',\n"," 'nagaland.csv',\n"," 'puducherry.csv',\n"," 'sikkim.csv',\n"," 'kerala.csv',\n"," 'andaman.csv']"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["states_w_eng_names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1466520,"status":"ok","timestamp":1718745683213,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"gzv-sntw9WEj","outputId":"2039dec1-2823-473f-f469-34168fa550bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting processing for andhra\n","finished processing for andhra\n","starting processing for arunachal\n","finished processing for arunachal\n","starting processing for dadra\n","finished processing for dadra\n","starting processing for daman\n","finished processing for daman\n","starting processing for delhi\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-45-67fe629f8da6>:25: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for delhi\n","starting processing for goa\n","finished processing for goa\n","starting processing for jk\n","finished processing for jk\n","starting processing for manipur\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-45-67fe629f8da6>:25: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for manipur\n","starting processing for meghalaya\n","finished processing for meghalaya\n","starting processing for mizoram\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-45-67fe629f8da6>:25: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for mizoram\n","starting processing for nagaland\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-45-67fe629f8da6>:25: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for nagaland\n","starting processing for puducherry\n","finished processing for puducherry\n","starting processing for sikkim\n","finished processing for sikkim\n","starting processing for kerala\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-45-67fe629f8da6>:25: DtypeWarning: Columns (14,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for kerala\n","starting processing for andaman\n","finished processing for andaman\n"]}],"source":["for state in states_w_eng_names:\n","  state = state.split('.')[0]\n","  print(f\"starting processing for {state}\")\n","  process_lastnames(f'data/clean/{state}.csv', state)\n","  print(f\"finished processing for {state}\")"]},{"cell_type":"markdown","metadata":{"id":"HS6YVzd2Ow-U"},"source":["## Processing names that are not in english"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1718745817248,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"j0CjcqS6IttM","outputId":"3302cb59-b532-4b50-981c-ba0b35a147c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 382024519\n","-rw------- 1 root root 30371244722 May 24 23:04 west_bengal.csv\n","-rw------- 1 root root 94178659023 May 27 22:45 uttar_pradesh.csv\n","-rw------- 1 root root 30799628245 May 27 22:45 rajasthan.csv\n","-rw------- 1 root root 13019509069 May 27 22:45 punjab.csv\n","-rw------- 1 root root 24524158426 May 27 22:45 odisha.csv\n","-rw------- 1 root root 30171537617 May 27 22:45 madhya_pradesh.csv\n","-rw------- 1 root root  5786439167 May 27 22:45 karnataka.csv\n","-rw------- 1 root root 10790608302 May 27 22:45 haryana.csv\n","-rw------- 1 root root 16324706456 May 27 22:45 gujarat.csv\n","-rw------- 1 root root 64123876606 May 27 22:45 bihar.csv\n","-rw------- 1 root root  6385059843 May 27 22:45 assam.csv\n","-rw------- 1 root root  4881172872 May 27 22:45 uttarakhand.csv\n","-rw------- 1 root root  2263448186 May 27 22:45 tripura.csv\n","-rw------- 1 root root  8522263084 May 27 22:45 telangana.csv\n","-rw------- 1 root root 32063522554 May 27 22:45 tamil_nadu.csv\n","-rw------- 1 root root 13816008964 May 27 22:45 jharkhand.csv\n","-rw------- 1 root root  2784762272 May 27 22:45 himachal_pradesh.csv\n","-rw------- 1 root root   379389530 May 27 22:45 chandigarh.csv\n"]}],"source":["# below are the states that have names in english\n","!ls -ltr data/non_english/ | grep -v \"_ln\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":530,"status":"ok","timestamp":1718745897305,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"VoRFQGQ3O3QS","outputId":"03bb5dfb-75f1-49dd-8126-0745f9769cc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["18\n"]}],"source":["# total states\n","!ls -ltr data/non_english/ | grep -v \"_ln\" | grep \"csv\" | wc -l"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1718745914716,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"gtdm67FCPPXd","outputId":"de4f2692-97b0-4099-c85b-30318ed2394d"},"outputs":[{"name":"stdout","output_type":"stream","text":["29G\tdata/non_english/west_bengal.csv\n","88G\tdata/non_english/uttar_pradesh.csv\n","29G\tdata/non_english/rajasthan.csv\n","13G\tdata/non_english/punjab.csv\n","23G\tdata/non_english/odisha.csv\n","29G\tdata/non_english/madhya_pradesh.csv\n","5.4G\tdata/non_english/karnataka.csv\n","11G\tdata/non_english/haryana.csv\n","16G\tdata/non_english/gujarat.csv\n","60G\tdata/non_english/bihar.csv\n","6.0G\tdata/non_english/assam.csv\n","4.6G\tdata/non_english/uttarakhand.csv\n","2.2G\tdata/non_english/tripura.csv\n","8.0G\tdata/non_english/telangana.csv\n","30G\tdata/non_english/tamil_nadu.csv\n","13G\tdata/non_english/jharkhand.csv\n","2.6G\tdata/non_english/himachal_pradesh.csv\n","362M\tdata/non_english/chandigarh.csv\n"]}],"source":["# get size of the files\n","!ls -ltr data/non_english/ | grep -v \"_ln\" | awk '{print $9}' | xargs -I % du -sh data/non_english/%"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":460,"status":"ok","timestamp":1718746730954,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"Rd2PYBmYPVod","outputId":"ab613c1b-5770-4dfb-89fe-737c9e488d42"},"outputs":[{"name":"stdout","output_type":"stream","text":["1G\tdata/non_english/chandigarh.csv\n","3G\tdata/non_english/himachal_pradesh.csv\n","3G\tdata/non_english/tripura.csv\n","5G\tdata/non_english/uttarakhand.csv\n","6G\tdata/non_english/assam.csv\n","6G\tdata/non_english/karnataka.csv\n","8G\tdata/non_english/telangana.csv\n","11G\tdata/non_english/haryana.csv\n","13G\tdata/non_english/jharkhand.csv\n","13G\tdata/non_english/punjab.csv\n","16G\tdata/non_english/gujarat.csv\n","23G\tdata/non_english/odisha.csv\n","29G\tdata/non_english/madhya_pradesh.csv\n","29G\tdata/non_english/rajasthan.csv\n","29G\tdata/non_english/west_bengal.csv\n","30G\tdata/non_english/tamil_nadu.csv\n","60G\tdata/non_english/bihar.csv\n","88G\tdata/non_english/uttar_pradesh.csv\n"]}],"source":["# sort based on size\n","!ls -ltr data/non_english/ | grep -v \"_ln\" | awk '{print $9}' |  xargs -I % du -sh --block-size=G data/non_english/% | sort -k1,1 -h"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1718746936479,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"opNLqsv5RZix","outputId":"e40ea10b-db9f-434a-e367-09d028dde7f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["1G\tdata/non_english/chandigarh.csv\n","3G\tdata/non_english/himachal_pradesh.csv\n","3G\tdata/non_english/tripura.csv\n","5G\tdata/non_english/uttarakhand.csv\n","6G\tdata/non_english/assam.csv\n","6G\tdata/non_english/karnataka.csv\n","8G\tdata/non_english/telangana.csv\n","11G\tdata/non_english/haryana.csv\n","13G\tdata/non_english/jharkhand.csv\n","13G\tdata/non_english/punjab.csv\n","16G\tdata/non_english/gujarat.csv\n"]}],"source":["# with 84 GB RAM we can fit till 16G\n","# so get files that are less than 20G\n","!ls -ltr data/non_english/ | grep -v \"_ln\" | awk '{print $9}' |  xargs -I % du -sh --block-size=G data/non_english/% \\\n","  | sort -k1,1 -h | awk '$1 ~ /G$/ && substr($1, 1, length($1)-1) + 0 < 20'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQpxRitxTPEE"},"outputs":[],"source":["states_non_eng_lt_20g = !ls -ltr data/non_english/ | grep -v \"_ln\" | awk '{print $9}' |  xargs -I % du -sh --block-size=G data/non_english/% \\\n","  | sort -k1,1 -h | awk '$1 ~ /G$/ && substr($1, 1, length($1)-1) + 0 < 20' | awk '{print $2}'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718747018999,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"4mA9GqvpTgFL","outputId":"817e5af6-8991-4c04-ba75-55fabbe374e7"},"outputs":[{"data":{"text/plain":["['data/non_english/chandigarh.csv',\n"," 'data/non_english/himachal_pradesh.csv',\n"," 'data/non_english/tripura.csv',\n"," 'data/non_english/uttarakhand.csv',\n"," 'data/non_english/assam.csv',\n"," 'data/non_english/karnataka.csv',\n"," 'data/non_english/telangana.csv',\n"," 'data/non_english/haryana.csv',\n"," 'data/non_english/jharkhand.csv',\n"," 'data/non_english/punjab.csv',\n"," 'data/non_english/gujarat.csv']"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["states_non_eng_lt_20g"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3254674,"status":"ok","timestamp":1718750518703,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"TdzeKBL8ThcU","outputId":"79957610-f4e2-44c9-ed95-c11ac5f84a2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting processing for chandigarh\n","finished processing for chandigarh\n","starting processing for himachal_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (8,9,10,16,17,18,29,30,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for himachal_pradesh\n","starting processing for tripura\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (0,10,18,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for tripura\n","starting processing for uttarakhand\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (0,5,16,20,21,32,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for uttarakhand\n","starting processing for assam\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (0,8,9,10,14,17,18,28,29,30,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for assam\n","starting processing for karnataka\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (0,5,14,17,20,31,34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for karnataka\n","starting processing for telangana\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (8,9,10,16,19) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for telangana\n","starting processing for haryana\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (0,5,15,17,32,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for haryana\n","starting processing for jharkhand\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (10,14,16,17,31,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for jharkhand\n","starting processing for punjab\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (8,10,14,17,20,28,30,33,35) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for punjab\n","starting processing for gujarat\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-70-71479c40cc55>:25: DtypeWarning: Columns (0,15,17,31,33) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["finished processing for gujarat\n"]}],"source":["# trim data/non_english\n","for state in states_non_eng_lt_20g:\n","  state = state.split('.')[0].split('/')[-1]\n","  print(f\"starting processing for {state}\")\n","  process_lastnames(f'data/non_english/{state}.csv', state, path=\"data/final/non_eng\")\n","  print(f\"finished processing for {state}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrXuCDazUcCB"},"outputs":[],"source":["states_non_eng_gt_20g = !ls -ltr data/non_english/ | grep -v \"_ln\" | awk '{print $9}' |  xargs -I % du -sh --block-size=G data/non_english/% \\\n","  | sort -k1,1 -h | awk '$1 ~ /G$/ && substr($1, 1, length($1)-1) + 0 > 20'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1719012850396,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"glkk3qmnhDo0","outputId":"3f9a89f0-70d3-4375-d013-e1b82735df41"},"outputs":[{"data":{"text/plain":["['23G\\tdata/non_english/odisha.csv',\n"," '29G\\tdata/non_english/madhya_pradesh.csv',\n"," '29G\\tdata/non_english/rajasthan.csv',\n"," '29G\\tdata/non_english/west_bengal.csv',\n"," '30G\\tdata/non_english/tamil_nadu.csv',\n"," '60G\\tdata/non_english/bihar.csv',\n"," '88G\\tdata/non_english/uttar_pradesh.csv']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["states_non_eng_gt_20g"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":488,"status":"ok","timestamp":1719012855986,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"dpek5NTzhYEz","outputId":"27c53711-1f11-4e55-b3a5-c3d974deb3f4"},"outputs":[{"data":{"text/plain":["2"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import math\n","math.ceil(int(\"23G\\tdata/non_english/odisha.csv\".split('\\t')[0].split('G')[0])/15)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjWQyuXISLYJ"},"outputs":[],"source":["def merge_agg(files, state):\n","    dataframes = [pd.read_csv(file) for file in files]\n","    combined_df = pd.concat(dataframes, ignore_index=True)\n","\n","    aggregated_data = combined_df.groupby('last_name')['count'].sum().reset_index()\n","    aggregated_data.columns = ['last_name', 'count']\n","    aggregated_data['state'] = state\n","\n","    aggregated_data.to_csv(f'data/final/non_eng/{state}_ln.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocwb6DvmhEgx","outputId":"1daff598-8410-4adb-e03c-ad3b245d4368"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting processing for odisha with size 23G, split size 2\n","data/non_eng_split/aa\n","odisha\n","\n","data/non_eng_split/ab\n","odisha\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (8,28) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","finished processing for odisha\n","starting processing for madhya_pradesh with size 29G, split size 2\n","data/non_eng_split/aa\n","madhya_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,14,17,31,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ab\n","madhya_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,14,15,16,17,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","finished processing for madhya_pradesh\n","starting processing for rajasthan with size 29G, split size 2\n","data/non_eng_split/aa\n","rajasthan\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (5,15,16,17,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ab\n","rajasthan\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (5,15,16,17,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","finished processing for rajasthan\n","starting processing for west_bengal with size 29G, split size 2\n","data/non_eng_split/aa\n","west_bengal\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (7,10,14,15,16,17,18,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ab\n","west_bengal\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (7,10,14,15,16,17,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","finished processing for west_bengal\n","starting processing for tamil_nadu with size 30G, split size 2\n","data/non_eng_split/aa\n","tamil_nadu\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (8,9,10,14,15,17,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ab\n","tamil_nadu\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (10,14,15,17,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","finished processing for tamil_nadu\n","starting processing for bihar with size 60G, split size 4\n","data/non_eng_split/aa\n","bihar\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (5,16,17,18,21,34,35,37,38,39,40,41,49,50,53) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ab\n","bihar\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (5,14,17,18,20,33,34,35,36,37,38,39,40,41,47,50,52) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ac\n","bihar\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (5,14,15,16,17,18,19,20,21,31,33,34,35,36,37,38,39,40,41,47,48,49,50,51,52,53) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ad\n","bihar\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (5,17,18,20,32,34,36,37,38,39,40,41,50,52) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","finished processing for bihar\n","starting processing for uttar_pradesh with size 88G, split size 6\n","data/non_eng_split/aa\n","uttar_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,5,8,10,14,17,29,31,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ab\n","uttar_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,5,10,14,15,16,17,18,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ac\n","uttar_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,5,10,14,17,31,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ad\n","uttar_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,5,10,14,15,16,17,18,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/ae\n","uttar_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,5,10,14,15,16,17,18,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]},{"name":"stdout","output_type":"stream","text":["\n","data/non_eng_split/af\n","uttar_pradesh\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-31-71479c40cc55>:25: DtypeWarning: Columns (0,5,10,14,16,17,31,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n"]}],"source":["for state in states_non_eng_gt_20g:\n","  size = state.split('\\t')[0]\n","  split_size = math.ceil(int(size.split('G')[0])/15)\n","  file_path = state.split('\\t')[1]\n","  state = file_path.split('.')[0].split('/')[-1]\n","  print(f\"starting processing for {state} with size {size}, split size {split_size}\")\n","  # split file based on split_size\n","  !split -n $split_size $file_path data/non_eng_split/\n","  # get split files\n","  split_files = !find data/non_eng_split/ -type f\n","  # process each split file\n","  file_no = 1\n","  final_files = []\n","  for split_file in split_files:\n","    if 'headers' in split_file:\n","      continue\n","    print(split_file)\n","    print(state)\n","    # get headers\n","    if file_no == 1:\n","      !head -1 $split_file > ./data/non_eng_split/headers.csv\n","    else:\n","      # remove first line\n","      !sed -i '1d' $split_file\n","      # add headers to first line\n","      !cat ./data/non_eng_split/headers.csv $split_file > ./data/non_eng_split/tmp.csv\n","      !mv ./data/non_eng_split/tmp.csv $split_file\n","    # remove last line\n","    !sed -i '$d' $split_file\n","    file_name = split_file.split('/')[-1]\n","    process_lastnames(split_file, file_name, path=\"data/non_eng_split\")\n","    file_no = file_no + 1\n","    final_files.append(f\"{split_file}_ln.csv\")\n","    print()\n","  merge_agg(final_files, state)\n","  # remove all files in non_eng_split\n","  !rm -rf data/non_eng_split/*\n","  print(f\"finished processing for {state}\")"]},{"cell_type":"markdown","metadata":{"id":"3XhytBp58RJI"},"source":["## Now convert all non-english languages to english"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8288,"status":"ok","timestamp":1719941268611,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"IMZHuXugR4n8","outputId":"100bdcd6-477a-4cdc-ba99-e016f3b12397"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.35.8-py3-none-any.whl (328 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/328.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.8\n"]}],"source":["!pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6233,"status":"ok","timestamp":1719941278060,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"OCQ6PxihSVuU","outputId":"d02ccc25-1e46-4c2f-bbec-507ed76ee504"},"outputs":[{"name":"stdout","output_type":"stream","text":["OpenAI API key: ··········\n"]}],"source":["import getpass\n","from openai import OpenAI\n","\n","OPENAI_API_KEY = getpass.getpass(\"OpenAI API key: \")\n","client = OpenAI(api_key=OPENAI_API_KEY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI91AetkWFMc"},"outputs":[],"source":["import os\n","import pandas as pd\n","import csv\n","import time\n","import requests\n","import json\n","\n","def generate(prompt):\n","  response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","      {\"role\": \"user\", \"content\": prompt}\n","    ]\n","  )\n","  return response.choices[0].message.content\n","\n","# Function to divide names into chunks\n","def chunks(lst, n):\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]\n","\n","\n","# Function to get already processed names\n","def get_processed_names(file):\n","    if os.path.exists(file):\n","        with open(file, 'r') as f:\n","            reader = csv.DictReader(f)\n","            return {row['Name'] for row in reader}\n","    else:\n","        # create file\n","        with open(file, 'w') as f:\n","            writer = csv.DictWriter(f, fieldnames=['Name', 'Translated'])\n","            writer.writeheader()\n","        return set()\n","\n","\n","def transliterate(file):\n","  df = pd.read_csv(file)\n","  unique_names = df['last_name'].unique()\n","  print(f\"total names: {len(unique_names)}\")\n","  state = file.split('.')[0]\n","  translated_file = f\"{state}_trans.csv\"\n","\n","  # Get already processed names\n","  processed_names = get_processed_names(translated_file)\n","  print(f\"till now processed: {len(processed_names)}\")\n","\n","  prompt = \"\"\"\n","  Transliterate the given text to English. Do not translate.\n","  Respond in json format - {\"key\": \"value\"} where value is the transliterated text of key.\n","  Below is the example for language hindi.\n","\n","  input:  'चंचला', 'रानी', 'दास', 'विकास'\n","  output:  {'चंचला': 'Chanchala', 'रानी': 'Rani', 'दास': 'Das','विकास': 'Vikas'}\n","\n","  \"\"\"\n","\n","  with open(translated_file, 'a', newline='') as csvfile:\n","      fieldnames = ['Name', 'Translated']\n","      writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","      # If file is empty write the header\n","      if csvfile.tell() == 0:\n","          writer.writeheader()\n","\n","      c = 0\n","      # Iterate over names in chunks\n","      main_chunk = []\n","      for chunk in chunks(list(unique_names), 50):\n","          if c!=0 and c%50 == 0:\n","              print(f\"done processing {c * 50}\")\n","          c = c + 1\n","\n","          # Skip names that have been processed\n","          chunk = [name for name in chunk if name not in processed_names]\n","          if not chunk:\n","              continue\n","\n","          # Append the chunk to the main chunk\n","          main_chunk.extend(chunk)\n","          # if length of main chunk is less 20, add next chunk\n","          if len(main_chunk) < 20:\n","              continue\n","\n","          fail = False\n","          while True:\n","              try:\n","                  # Make the API call\n","                  # print(prompt + ', '.join(chunk))\n","                  chat_response = generate(prompt + ', '.join(main_chunk))\n","                  #print(chat_response)\n","              except Exception as e:\n","                  print(e)\n","                  time.sleep(2)  # Sleep for 2 seconds and then retry\n","                  fail = True\n","                  #continue\n","\n","              break  # If no errors, break the loop\n","\n","          if fail:\n","            continue\n","          try:\n","            if chat_response:\n","              results = json.loads(chat_response)\n","              for name in results:\n","                  writer.writerow({'Name': name, 'Translated': results[name]})\n","              csvfile.flush()  # Ensure data is written after each batch\n","          except Exception as e:\n","            print(e)\n","          time.sleep(2)  # Sleep for second\n","          main_chunk = []\n","\n","def merge_df(file1, file2):\n","  df1 = pd.read_csv(file1)\n","  df2 = pd.read_csv(file2)\n","  df2 = df2.rename(columns={'Name': 'last_name'})\n","  df3 = pd.merge(df1, df2, on='last_name', how='outer')\n","  df3.to_csv(f\"{file1.split('.')[0]}_processed.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1719941289154,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"iHVGyqoSUH8P","outputId":"c151c4ec-b05a-4929-b704-e1ec70bc044e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab/instate_v2/data/final/non_eng\n"]}],"source":["%cd data/final/non_eng"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1719941293428,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"8vy71JIxT9fc","outputId":"55477647-daa5-4236-e9a8-bec8a2931481"},"outputs":[{"output_type":"stream","name":"stdout","text":["-rw------- 1 root root  198754 Jun 18 21:49 himachal_pradesh_ln.csv\n","-rw------- 1 root root  141842 Jun 18 21:50 tripura_ln.csv\n","-rw------- 1 root root  415775 Jun 18 21:53 uttarakhand_ln.csv\n","-rw------- 1 root root  443221 Jun 18 21:57 assam_ln.csv\n","-rw------- 1 root root 2307232 Jun 18 22:00 karnataka_ln.csv\n","-rw------- 1 root root 5011806 Jun 18 22:06 telangana_ln.csv\n","-rw------- 1 root root  537318 Jun 18 22:13 haryana_ln.csv\n","-rw------- 1 root root 1308216 Jun 18 22:23 jharkhand_ln.csv\n","-rw------- 1 root root  396258 Jun 18 22:32 punjab_ln.csv\n","-rw------- 1 root root   39525 Jun 18 22:41 gujarat_ln.csv\n","-rw------- 1 root root  192120 Jun 22 00:01 chandigarh_ln.csv\n","-rw------- 1 root root 2003685 Jun 22 01:00 odisha_ln.csv\n","-rw------- 1 root root 2783105 Jun 22 01:36 madhya_pradesh_ln.csv\n","-rw------- 1 root root  705463 Jun 22 02:09 rajasthan_ln.csv\n","-rw------- 1 root root 2586427 Jun 22 02:55 west_bengal_ln.csv\n","-rw------- 1 root root 1064265 Jun 22 03:31 tamil_nadu_ln.csv\n","-rw------- 1 root root  818879 Jun 22 04:56 bihar_ln.csv\n","-rw------- 1 root root 1385552 Jun 22 07:08 uttar_pradesh_ln.csv\n"]}],"source":["!ls -ltr *_ln.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-62RmtglWF3c"},"outputs":[],"source":["non_eng_files = !ls -ltr *_ln.csv | awk '{print $9}'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719941311876,"user":{"displayName":"Rajashekar Chintalapati","userId":"03596288833202137831"},"user_tz":420},"id":"p-dnMFBwWJqG","outputId":"8f744a5f-b398-4e7c-f480-4b56ccd1c6c3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['himachal_pradesh_ln.csv',\n"," 'tripura_ln.csv',\n"," 'uttarakhand_ln.csv',\n"," 'assam_ln.csv',\n"," 'karnataka_ln.csv',\n"," 'telangana_ln.csv',\n"," 'haryana_ln.csv',\n"," 'jharkhand_ln.csv',\n"," 'punjab_ln.csv',\n"," 'gujarat_ln.csv',\n"," 'chandigarh_ln.csv',\n"," 'odisha_ln.csv',\n"," 'madhya_pradesh_ln.csv',\n"," 'rajasthan_ln.csv',\n"," 'west_bengal_ln.csv',\n"," 'tamil_nadu_ln.csv',\n"," 'bihar_ln.csv',\n"," 'uttar_pradesh_ln.csv']"]},"metadata":{},"execution_count":9}],"source":["non_eng_files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLiz8h8BU10V","outputId":"4d309f8a-43d3-4c49-a0b5-0eb2b4c19895"},"outputs":[{"output_type":"stream","name":"stdout","text":["processing himachal_pradesh_ln.csv\n","total names: 5488\n","till now processed: 5516\n","done processing 2500\n","done processing 5000\n","finished processing himachal_pradesh_ln.csv\n","processing tripura_ln.csv\n","total names: 4687\n","till now processed: 4701\n","done processing 2500\n","finished processing tripura_ln.csv\n","processing uttarakhand_ln.csv\n","total names: 12786\n","till now processed: 12832\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","finished processing uttarakhand_ln.csv\n","processing assam_ln.csv\n","total names: 16367\n","till now processed: 16477\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","finished processing assam_ln.csv\n","processing karnataka_ln.csv\n","total names: 67679\n","till now processed: 68171\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","done processing 17500\n","done processing 20000\n","done processing 22500\n","done processing 25000\n","done processing 27500\n","done processing 30000\n","done processing 32500\n","done processing 35000\n","done processing 37500\n","done processing 40000\n","done processing 42500\n","done processing 45000\n","done processing 47500\n","done processing 50000\n","done processing 52500\n","done processing 55000\n","done processing 57500\n","done processing 60000\n","done processing 62500\n","done processing 65000\n","done processing 67500\n","finished processing karnataka_ln.csv\n","processing telangana_ln.csv\n","total names: 146839\n","till now processed: 148677\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","done processing 17500\n","done processing 20000\n","done processing 22500\n","done processing 25000\n","done processing 27500\n","done processing 30000\n","done processing 32500\n","done processing 35000\n","done processing 37500\n","done processing 40000\n","done processing 42500\n","done processing 45000\n","done processing 47500\n","done processing 50000\n","done processing 52500\n","done processing 55000\n","done processing 57500\n","done processing 60000\n","done processing 62500\n","done processing 65000\n","done processing 67500\n","done processing 70000\n","done processing 72500\n","done processing 75000\n","done processing 77500\n","done processing 80000\n","done processing 82500\n","done processing 85000\n","done processing 87500\n","done processing 90000\n","done processing 92500\n","done processing 95000\n","done processing 97500\n","done processing 100000\n","done processing 102500\n","done processing 105000\n","Expecting value: line 1 column 400 (char 399)\n","done processing 107500\n","done processing 110000\n","done processing 112500\n","done processing 115000\n","done processing 117500\n","done processing 120000\n","Expecting ':' delimiter: line 2 column 17 (char 18)\n","done processing 122500\n","done processing 125000\n","done processing 127500\n","done processing 130000\n","done processing 132500\n","done processing 135000\n","done processing 137500\n","done processing 140000\n","done processing 142500\n","done processing 145000\n","finished processing telangana_ln.csv\n","processing haryana_ln.csv\n","total names: 19053\n","till now processed: 19093\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","done processing 17500\n","finished processing haryana_ln.csv\n","processing jharkhand_ln.csv\n","total names: 42371\n","till now processed: 42632\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","done processing 17500\n","done processing 20000\n","done processing 22500\n","done processing 25000\n","done processing 27500\n","done processing 30000\n","done processing 32500\n","done processing 35000\n","done processing 37500\n","done processing 40000\n","finished processing jharkhand_ln.csv\n","processing punjab_ln.csv\n","total names: 15609\n","till now processed: 15632\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","finished processing punjab_ln.csv\n","processing gujarat_ln.csv\n","total names: 1256\n","till now processed: 1254\n","finished processing gujarat_ln.csv\n","processing chandigarh_ln.csv\n","total names: 6346\n","till now processed: 6347\n","done processing 2500\n","done processing 5000\n","finished processing chandigarh_ln.csv\n","processing odisha_ln.csv\n","total names: 69553\n","till now processed: 43739\n","done processing 2500\n","done processing 5000\n","done processing 7500\n","Expecting property name enclosed in double quotes: line 1 column 280 (char 279)\n","Invalid \\uXXXX escape: line 17 column 11 (char 413)\n","done processing 10000\n","done processing 12500\n","done processing 15000\n","done processing 17500\n","done processing 20000\n","Expecting ':' delimiter: line 1 column 322 (char 321)\n","done processing 22500\n","done processing 25000\n","done processing 27500\n","done processing 30000\n","done processing 32500\n","done processing 35000\n","done processing 37500\n","done processing 40000\n","Expecting ':' delimiter: line 16 column 15 (char 405)\n","done processing 42500\n","done processing 45000\n","done processing 47500\n","Expecting property name enclosed in double quotes: line 51 column 1 (char 1360)\n","'utf-8' codec can't encode character '\\ud83c' in position 8: surrogates not allowed\n","done processing 50000\n","Expecting ':' delimiter: line 1 column 993 (char 992)\n","Unterminated string starting at: line 1 column 138 (char 137)\n","Expecting property name enclosed in double quotes: line 1 column 915 (char 914)\n","done processing 52500\n","Unterminated string starting at: line 1 column 1063 (char 1062)\n","Invalid control character at: line 1 column 568 (char 567)\n","Unterminated string starting at: line 1 column 630 (char 629)\n","done processing 55000\n","Expecting property name enclosed in double quotes: line 1 column 472 (char 471)\n","Expecting property name enclosed in double quotes: line 49 column 3 (char 1107)\n","done processing 57500\n","Invalid \\uXXXX escape: line 1 column 977 (char 976)\n","Unterminated string starting at: line 14 column 22 (char 326)\n","done processing 60000\n","Unterminated string starting at: line 26 column 13 (char 558)\n","done processing 62500\n","Unterminated string starting at: line 4 column 13 (char 62)\n","Unterminated string starting at: line 44 column 15 (char 1104)\n","Unterminated string starting at: line 8 column 12 (char 134)\n","Invalid control character at: line 1 column 972 (char 971)\n","Unterminated string starting at: line 1 column 1103 (char 1102)\n","Unterminated string starting at: line 4 column 14 (char 64)\n","done processing 65000\n","Unterminated string starting at: line 1 column 371 (char 370)\n","Unterminated string starting at: line 1 column 368 (char 367)\n","Unterminated string starting at: line 1 column 916 (char 915)\n","Unterminated string starting at: line 36 column 13 (char 767)\n","Unterminated string starting at: line 44 column 13 (char 973)\n","Expecting property name enclosed in double quotes: line 52 column 1 (char 1173)\n","done processing 67500\n","Expecting property name enclosed in double quotes: line 1 column 209 (char 208)\n","Invalid control character at: line 1 column 718 (char 717)\n","Unterminated string starting at: line 1 column 724 (char 723)\n","Expecting ',' delimiter: line 1 column 555 (char 554)\n","finished processing odisha_ln.csv\n","processing madhya_pradesh_ln.csv\n","total names: 75717\n","till now processed: 0\n","Unterminated string starting at: line 1 column 779 (char 778)\n","Unterminated string starting at: line 1 column 894 (char 893)\n","done processing 2500\n","Unterminated string starting at: line 1 column 425 (char 424)\n","Expecting property name enclosed in double quotes: line 51 column 1 (char 1201)\n","Unterminated string starting at: line 1 column 713 (char 712)\n","done processing 5000\n","Unterminated string starting at: line 15 column 11 (char 309)\n","Unterminated string starting at: line 1 column 224 (char 223)\n","done processing 7500\n","Unterminated string starting at: line 1 column 543 (char 542)\n","Invalid control character at: line 1 column 709 (char 708)\n","Unterminated string starting at: line 19 column 14 (char 425)\n","Invalid control character at: line 1 column 816 (char 815)\n","Unterminated string starting at: line 1 column 494 (char 493)\n","done processing 10000\n","Unterminated string starting at: line 1 column 976 (char 975)\n","done processing 12500\n","Unterminated string starting at: line 4 column 15 (char 66)\n","Invalid control character at: line 1 column 437 (char 436)\n","Invalid control character at: line 1 column 618 (char 617)\n","done processing 15000\n","done processing 17500\n","done processing 20000\n","Unterminated string starting at: line 1 column 456 (char 455)\n","Unterminated string starting at: line 1 column 902 (char 901)\n","Expecting value: line 50 column 12 (char 1150)\n","done processing 22500\n","done processing 25000\n","Unterminated string starting at: line 35 column 13 (char 725)\n","Expecting value: line 1 column 516 (char 515)\n","done processing 27500\n","Unterminated string starting at: line 49 column 12 (char 1129)\n","Unterminated string starting at: line 1 column 447 (char 446)\n","Unterminated string starting at: line 35 column 14 (char 786)\n","done processing 30000\n","Unterminated string starting at: line 43 column 14 (char 927)\n","Unterminated string starting at: line 1 column 231 (char 230)\n","Unterminated string starting at: line 1 column 545 (char 544)\n","Invalid control character at: line 1 column 414 (char 413)\n","done processing 32500\n","Unterminated string starting at: line 1 column 239 (char 238)\n","done processing 35000\n","Unterminated string starting at: line 1 column 244 (char 243)\n","done processing 37500\n","Unterminated string starting at: line 1 column 739 (char 738)\n","Unterminated string starting at: line 1 column 421 (char 420)\n","Expecting ':' delimiter: line 1 column 447 (char 446)\n","done processing 40000\n"]}],"source":["for file in non_eng_files:\n","  print(f\"processing {file}\")\n","  transliterate(file)\n","  merge_df(file, f\"{file.split('.')[0]}_trans.csv\")\n","  print(f\"finished processing {file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ap38jnR9WDum"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"1FM32p5YfGDS7kr9rV2KQMs_0gsvOCyFq","authorship_tag":"ABX9TyPiepiRQ08IrPIjoKWqFAX/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}